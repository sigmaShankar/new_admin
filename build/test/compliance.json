{
    "Data Accountability and Transparency Act 2020.": {
        "regulatation": [
  
            {
                "name": "PROHIBITION ON DISCRIMINATION IN PUBLIC ACCOMMODATIONS.—",
                "details": [
                    "<pre> (1) IN GENERAL.—It is unlawful for a data aggregator to collect, use, or share personal data in a manner that segregates, discriminates in, or otherwise makes unavailable the goods, services, facilities, privileges, advantages, or accommodations of any place of public accommodation on the basis of a protected class.<br />      (1.a) BURDEN OF PROOF.—The burden of proof for disparate impact cases set forth in subsection <br/>      (2.a) Applies to cases with respect to this subsection.<br /> (3) INTERFERENCE WITH RIGHTS AND PRIVILEGES.—It is unlawful for a data aggregator to—<br />      (2.a) withhold, deny, deprive, or attempt to withhold, deny, or deprive any individual of any right or privilege secured by this subsection;(B) intimidate, threaten, or coerce, or attempt to intimidate, threaten, or coerce any individual with the purpose of interfering with any right or privilege secured by this subsection; or <br /> (C) punish or attempt to punish any individual for exercising or attempting to exercise any right or privilege secured by this subsection. </pre>"
                ]
            },
            {
                "name": "BURDEN OF PROOF FOR DISPARATE IMPACT.",
                "details": [
                    "<pre>  If the use of personal data causes a disparate impact on the basis of a protected class under subsection (a) or (b), the data aggregator has the burden of demonstrating that such use of personal data—(1) is not intentionally discriminatory;(2) is strictly necessary to achieve one or more substantial legitimate, non discriminatory interests; and(3) there is no reasonable alternative policy or practice that could serve the interest described in paragraph (2) with a less discriminatory effect. </pre>"
                ]
            },
            {
                "name": "SEC. 105. ALGORITHMIC ACCOUNTABILITY (a) IN GENERAL.",
                "details": [
                    "<pre>  If a data aggregator utilizes automated decision systems, the data aggregator shall perform—(1) continuous and automated testing for bias on the basis of a protected class; and(2) continuous and automated testing for disparate impact on the basis of a protected class as required by the Agency. </pre>"
                ]
            },
            {
                "name": "SEC. 105. ALGORITHMIC ACCOUNTABILITY (b) REQUIREMENT FOR SIMILAR METHODOLOGY.",
                "details": [
                    "<pre>  When evaluating an automated decision system against other less discriminatory alternatives, similar methodology shall be used to create the alternatives.</pre>"
                ]
            },
            {
                "name": "SEC. 105. ALGORITHMIC ACCOUNTABILITY (c) REPORTING REQUIREMENTS",
                "details": [
                    "<pre> For any automated decision system data aggregator shall provide the Agency—  (1) an automated decision system risk assessment— (A) within 90 days for any automated decision system currently in use;  (B) prior to the deployment of any new automated decision system; or  (C) as determined by the Director. (2) an automated decision system impact evaluation on a periodic basis as determined by the Director, but no less than annually.</pre>"
                ]
            }
        ]
    }
}